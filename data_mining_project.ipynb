{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification \n",
    "Breast cancer is a common cancer in women, and one of the major causes of death among women around the world. Invasive ductal carcinoma (IDC) is the most widespread type of breast cancer with about 80% of all diagnosed cases. IDC is cancer that began growing in a milk duct and has invaded the fibrous or fatty tissue of the breast outside of the duct. Early accurate diagnosis plays an important role in choosing the right treatment plan and improving survival rate among the patients. In recent years, efforts have been made to predict and detect all types of cancers by employing artificial intelligence. An appropriate dataset is the first essential step to achieve such a goal. This paper introduces a histopathological microscopy image dataset of 922 images related to 124 patients with IDC. The dataset has been published and is accessible through the web at: http://databiox.com. The distinctive feature of this dataset as compared to similar ones is that it contains an equal number of specimens from each of three grades of IDC, which leads to approximately 50 specimens for each grade.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Lobules_and_ducts_of_the_breast.jpg/504px-Lobules_and_ducts_of_the_breast.jpg)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In Kenya, cancer is the third leading cause of death after infectious and cardiovascular diseases. From 2012 to 2018, the annual incidence of cancer increased from 37,000 to 47,887 new cases.7 During the same period, annual cancer mortality rose almost 16%, from 28,500 to 32,987 cancer-related deaths. The number of new cancer cases is expected to rise by more than 120% over the next 2 decades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing and linear algebra\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from numba import njit\n",
    "\n",
    "#Data Visualiation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import cv2 as cv\n",
    "\n",
    "# Machine learning alogorithm\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input, Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import keras\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from os import listdir\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import random\n",
    "from pprint import pprint\n",
    "import time\n",
    "import copy\n",
    "from IPython.display import Image\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas();5\n",
    "\n",
    "print('import complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='output/stats.jpg', width = 1000, height = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "The original dataset consisted of 162 whole mount slide images of Breast Cancer (BCa) specimens scanned at 40x. From that, 277,524 patches of size 50 x 50 were extracted (198,738 IDC negative and 78,786 IDC positive). Each patch’s file name is of the format: uxXyYclassC.png — > example 10253idx5x1351y1101class0.png . Where u is the patient ID (10253idx5), X is the x-coordinate of where this patch was cropped from, Y is the y-coordinate of where this patch was cropped from, and C indicates the class where 0 is non-IDC and 1 is IDC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = listdir(\"output/archive/IDC_regular_ps50_idx5\")\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = listdir(\"output/archive\")\n",
    "len(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total number of about 280 sub-folders, let's take a peak into the folder and try and understand what those sub-folders are.\n",
    "\n",
    "Each subfolder seems to be the ID of the corresponding patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_file = listdir(\"output/archive/IDC_regular_ps50_idx5/13689\")\n",
    "len(patient_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file has 2 sub-folders, labeled 1 and 0\n",
    "\n",
    "1. Folder 0: Non-Invasive Ductal Carcinoma (IDC)\n",
    "\n",
    "2. Folder 1 : Invasive Ductal Carcinoma (IDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = listdir('output/archive/IDC_regular_ps50_idx5/13689/0')\n",
    "one = listdir('output/archive/IDC_regular_ps50_idx5/13689/1')\n",
    "print(f\"The number of NON IDC in Id 13689 is : {len(zero)}\")\n",
    "print(f\"The number of IDC in Id 13689 is : {len(one)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do we know about our data?\n",
    "\n",
    "1. Now that we have a good understanding of the file structure let's try and understand how much data we are about to process.\n",
    "\n",
    "2. How many patients do we have?\n",
    "\n",
    "    * It seems that we have a total number of 280 patients. \n",
    "    * This sample size is relatively small therefore we have to be careful not to overfit our model. We need to implement our model in such a way that it maximizes generalization.\n",
    "\n",
    "3. Each patient has a batch of patches that were extracted, therefore the total number of patches is likely much greater than 280.\n",
    "\n",
    "# NEXT STEP \n",
    "\n",
    "1. How many patches do we have in total?\n",
    "\n",
    "2. Which of them are IDC patches and which are Non-IDC?\n",
    "\n",
    "    * In order to train our model we need to feed our model each patch individually, therefore each patch will act as an input.\n",
    "\n",
    "    * The snippet below loops through the entire file structure and extracts the total number of crops for each of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 'output/archive/IDC_regular_ps50_idx5/'\n",
    "patient_ids = listdir(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_total = 0\n",
    "class_1_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in patient_ids:\n",
    "    class_0_files = listdir(train + patient_id + '/0')\n",
    "    class_1_files = listdir(train + patient_id + '/1')\n",
    "\n",
    "    class_0_total += len(class_0_files)\n",
    "    class_1_total += len(class_1_files) \n",
    "\n",
    "total_images = class_0_total + class_1_total\n",
    "    \n",
    "print(f'Number of patches in Class 0: {class_0_total}')\n",
    "print(f'Number of patches in Class 1: {class_1_total}')\n",
    "print(f'Total number of patches: {total_images}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the image_path, patient_id, target and x & y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"patient_id\",'x','y',\"target\",\"path\"]\n",
    "data_rows = []\n",
    "i = 0\n",
    "iss = 0\n",
    "isss = 0\n",
    "\n",
    "# note that we loop through the classes after looping through the \n",
    "# patient ids so that we avoid splitting our data into [all class 0 then all class 1]\n",
    "for patient_id in patient_ids:\n",
    "    for c in [0,1]:\n",
    "        class_path = train + patient_id + '/' + str(c) + '/'\n",
    "        imgs = listdir(class_path)\n",
    "        \n",
    "        # Extracting Image Paths\n",
    "        img_paths = [class_path + img + '/' for img in imgs]\n",
    "        \n",
    "        # Extracting Image Coordinates\n",
    "        img_coords = [img.split('_',4)[2:4] for img in imgs]\n",
    "        x_coords = [int(coords[0][1:]) for coords in img_coords]\n",
    "        y_coords = [int(coords[1][1:]) for coords in img_coords]\n",
    "\n",
    "        for (path,x,y) in zip(img_paths,x_coords,y_coords):\n",
    "            values = [patient_id,x,y,c,path]\n",
    "            data_rows.append({k:v for (k,v) in zip(columns,values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new dataframe using the list of dicts that we generated above\n",
    "data = pd.DataFrame(data_rows)\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Now that we have set up our data, let's create a visual summary to help us draw some insights from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default theme\n",
    "sns.set(context='notebook', style='darkgrid', palette='colorblind', font='sans-serif', font_scale=1, rc=None)\n",
    "matplotlib.rcParams['figure.figsize'] =[8,8]\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_perc = data.groupby(\"patient_id\").target.value_counts()/ data.groupby(\"patient_id\").target.size()\n",
    "cancer_perc = cancer_perc.unstack()\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(25,5))\n",
    "\n",
    "# Plotting Frequency of Patches per Patient\n",
    "sns.distplot(data.groupby(\"patient_id\").size(), ax=ax[0], color=\"green\", kde=False, bins=20)\n",
    "ax[0].set_xlabel(\"Number of patches\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].set_title(\"How many patches do we have per patient?\")\n",
    "\n",
    "# Plotting Percentage of an image that is covered by Invasive Ductile Carcinoma\n",
    "sns.distplot(cancer_perc.loc[:, 1]*100, ax=ax[1], color=\"red\", kde=False, bins=20)\n",
    "ax[1].set_title(\"How much percentage of an image is covered by IDC?\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "ax[1].set_xlabel(\"% of patches with IDC\")\n",
    "\n",
    "# Plotting number of patches that show IDC\n",
    "sns.countplot(data.target, palette='pastel', ax=ax[2]);\n",
    "ax[2].set_ylabel(\"Count\")\n",
    "ax[2].set_xlabel(\"no(0) versus yes(1)\")\n",
    "ax[2].set_title(\"How many patches show IDC?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Healthy Tissue Patches Vs Cancerous Tissue Patches\n",
    "Let us now explore the visual differences between cancerous tissue cells, and healthy tissue cells. \n",
    "Usually partnering with a specialist is a good idea so that they can point the exact points of interest that differentiate the 2 from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tissue = np.random.choice(data[data.target==1].index.values, size=100, replace=False)\n",
    "negative_tissue = np.random.choice(data[data.target==0].index.values, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A ) Cancerous Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(n_rows,n_cols,figsize = (30,30))\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        # below is a counter to cycle through the image indexes\n",
    "        idx = positive_tissue[col + n_cols*row]\n",
    "        img = io.imread(data.loc[idx, \"path\"])\n",
    "        ax[row,col].imshow(img[:,:,:])\n",
    "        ax[row,col].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Non-Cancerous Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(n_rows,n_cols,figsize = (30,30))\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        # below is a counter to cycle through the image indices\n",
    "        idx = negative_tissue[col + n_cols*row]\n",
    "        img = io.imread(data.loc[idx, \"path\"])\n",
    "        ax[row,col].imshow(img[:,:,:])\n",
    "        ax[row,col].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Breast Tissue\n",
    "\n",
    "Earlier we extracted the coordinates of the cropped tissue cells, we can use those coordinates to reconstruct the whole breast tissue of the patient. This way we can explore how the diseased tissue looks when compared to the healthy tissue.\n",
    "\n",
    "We can also explore the most common places that the cancer tends to occur in. It would be interesting to plot a heatmap of the most common areas where the cancer appears.\n",
    "\n",
    "If position of the crop has significance then perhaps we can use it as an input feature for our model.\n",
    "\n",
    "To simplify things we will create a function that slices our existing dataframe and retrieves the values associated with a patient id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_df(patient_id):\n",
    "    return data.loc[data['patient_id']== patient_id,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 3\n",
    "n_imgs = n_rows*n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['pink', 'red']\n",
    "\n",
    "fig, ax = plt.subplots(n_rows,n_cols,figsize=(20, 22))\n",
    "\n",
    "patient_ids = np.random.choice( data.patient_id.unique(), size=n_imgs, replace=False)\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        patient_id = patient_ids[col + n_cols*row]\n",
    "        patient_df = get_patient_df(patient_id)\n",
    "        \n",
    "        ax[row,col].scatter(patient_df.x.values, \\\n",
    "                            patient_df.y.values, \\\n",
    "                            c=patient_df.target.values,\\\n",
    "                            cmap=ListedColormap(colors), s=20)\n",
    "        ax[row,col].set_title(\"patient \" + patient_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Insights\n",
    "\n",
    "1. Sometimes we don't have the full tissue information. It seems that tissue patches have been discarded or lost during preparation.\n",
    "2. Cancerous Tissue tends to appear in clusters rather than, being dispersed all over the place.\n",
    "\n",
    "### Repatching the Actual Breast Tissue Image\n",
    "\n",
    "Now it's time to go one step deeper with our EDA. Instead of plotting the target values using the x-y coordinates, we now plot the images themselves on their respective x-y coordinates. This will help us visualize how the cancerous tissue looks like from a macro perspective.\n",
    "\n",
    "uint8 is used unsigned 8 bit integer. And that is the range of pixel. We can't have pixel value more than 2^8 -1. Therefore, for images uint8 type is used. Whereas double is used to handle very big numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_breast_tissue(patient_id, df = data,pred = False, crop_dimension = [50,50]):\n",
    "    # Plotting Settings\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # Get patient dataframe\n",
    "    p_df = get_patient_df(patient_id)\n",
    "    # Get the dimensions of the breast tissue image\n",
    "    max_coord = np.max((*p_df.x,*p_df.y))\n",
    "    # Allocate an array to fill image pixels in,use uint8 type as you don't need an int over 255\n",
    "    grid = 255*np.ones(shape = (max_coord + crop_dimension[0], max_coord + crop_dimension[1], 3)).astype(np.uint8)\n",
    "    mask = 255*np.ones(shape = (max_coord + crop_dimension[0], max_coord + crop_dimension[1], 3)).astype(np.uint8)\n",
    "    # Replace array values with values of the image\n",
    "    for x,y,target,path in zip(p_df['x'],p_df['y'],p_df['target'],p_df['path']):\n",
    "        try:\n",
    "            img = io.imread(path)\n",
    "            # Replace array values with cropped image values\n",
    "            grid[y:y+crop_dimension[1],x:x+crop_dimension[0]] = img\n",
    "            # Check if target is cancerous or not\n",
    "            if target != 0:\n",
    "                # If the target is cancerous then, replace array values with the color blue\n",
    "                mask[y:y+crop_dimension[1],x:x+crop_dimension[0]] = [0,0,255]\n",
    "        except: pass\n",
    "    # if prediction is not specifies then show the image normally\n",
    "    if pred == False:\n",
    "        io.imshow(grid)\n",
    "        img = grid\n",
    "    # if prediction is specified then apply a mask to the areas that contain predicted cancerous cells\n",
    "    else:\n",
    "        # Specify the desired alpha value\n",
    "        alpha = 0.78\n",
    "        # This is step is very important, adding 2 numpy arrays sets the values to float64, which is why convert them back to uint8\n",
    "        img = (mask * (1.0 - alpha) + grid * alpha).astype('uint8')\n",
    "        io.imshow(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 3\n",
    "n_imgs = n_rows*n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n_rows,n_cols,figsize=(20, 27))\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        p_id = patient_ids[col + n_cols*row]\n",
    "        \n",
    "        img = visualise_breast_tissue(p_id, pred = True)\n",
    "        ax[row,col].grid(False)\n",
    "        ax[row,col].set_xticks([])\n",
    "        ax[row,col].set_yticks([])\n",
    "        ax[row,col].set_title(\"Breast tissue slice of patient: \" + p_id)        \n",
    "        ax[row,col].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file dir\n",
    "breast_img = glob('output/archive/IDC_regular_ps50_idx5/**/*.png', recursive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_img = []\n",
    "can_img = []\n",
    "\n",
    "for img in breast_img:\n",
    "    if img[-5] == '0' :\n",
    "        non_img.append(img)\n",
    "    \n",
    "    elif img[-5] == '1' :\n",
    "        can_img.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_num = len(non_img)\n",
    "can_num = len(can_img)\n",
    "        \n",
    "total_img_num = non_num + can_num\n",
    "        \n",
    "print('Number of Images in IDC (-): {}' .format(non_num))\n",
    "print('Number of Images in IDC (+) : {}' .format(can_num))\n",
    "print('Total Number of Images : {}' .format(total_img_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_non_img = random.sample(non_img, len(can_img))\n",
    "some_can_img = random.sample(can_img, len(can_img))\n",
    "\n",
    "non_img_arr = []\n",
    "can_img_arr = []\n",
    "\n",
    "for img in some_non_img:   \n",
    "    n_img = cv.imread(img, cv.IMREAD_COLOR)\n",
    "    n_img_size = cv.resize(n_img, (50, 50), interpolation = cv.INTER_LINEAR)\n",
    "    non_img_arr.append([n_img_size, 0])\n",
    "    \n",
    "for img in some_can_img:\n",
    "    c_img = cv.imread(img, cv.IMREAD_COLOR)\n",
    "    c_img_size = cv.resize(c_img, (50, 50), interpolation = cv.INTER_LINEAR)\n",
    "    can_img_arr.append([c_img_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "breast_img_arr = np.concatenate((non_img_arr, can_img_arr))\n",
    "random.shuffle(breast_img_arr)\n",
    "\n",
    "for feature, label in breast_img_arr:\n",
    "    X.append(feature)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print('X shape : {}' .format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_predict, y_train, y_true = train_test_split(X, y, test_size = 0.2, random_state = 128)\n",
    "\n",
    "rate = 0.8\n",
    "num = int(X.shape[0] * rate)\n",
    "\n",
    "X_test = X_train[num:]\n",
    "X_train = X_train[:num]\n",
    "\n",
    "y_test = y_train[num:]\n",
    "y_train = y_train[:num]\n",
    "\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)\n",
    "y_true = to_categorical(y_true, 2)\n",
    "\n",
    "print('X_train shape : {}' .format(X_train.shape))\n",
    "print('X_test shape : {}' .format(X_test.shape))\n",
    "print('X_predict shape : {}' .format(X_predict.shape))\n",
    "print('y_train shape : {}' .format(y_train.shape))\n",
    "print('y_test shape : {}' .format(y_test.shape))\n",
    "print('y_true shape : {}' .format(y_true.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\" X_train maximum value before scaling: {X_train.max()}\")\n",
    "#print(f\" X_test maximum value before scaling: {X_test.max()}\")\n",
    "#X_train = X_train / 255\n",
    "#X_test = X_test / 255\n",
    "#print(f\" X_train maximum value after scaling: {X_train.max()}\")\n",
    "#print(f\" X_test maximum value after scaling: {X_test.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks (CNN) \n",
    "CNN emerged from the study of the brain’s visual cortex, and they have been used in image recognition since the 1980s. According to Aurelien, CNNs have man‐\n",
    "aged to achieve superhuman performance on some complex visual tasks. Some of their application include:\n",
    "* Power image search services\n",
    "* Self-driving cars\n",
    "* Automatic video classification systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer\n",
    "\n",
    "Convolution is a linear operation that involves the multiplication of a set of weights with the input, much like a traditional neural network.\n",
    "\n",
    "Given that the technique was designed for two-dimensional input, the multiplication is performed between an array of input data and a two-dimensional array of weights, called a filter or a kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='output/conv.png', width = 1500, height = 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer\n",
    "\n",
    "Their goal is to subsample (i.e., shrink) the input image in order to reduce:\n",
    "* The computational load\n",
    "* The memory usage\n",
    "* The number of parameters (thereby limiting the risk of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='output/maxpool.png', width = 1500, height = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inp_shape = (50, 50, 3)):\n",
    "    inp = Input(inp_shape)\n",
    "    m = Conv2D(32, (3, 3) , padding=\"same\", activation='relu')(inp)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    m = Dropout(0.25)(m)\n",
    "    \n",
    "    m = Conv2D(64, (3, 3), padding=\"same\", activation='relu')(m)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    m = Dropout(0.25)(m)\n",
    "    \n",
    "    m = Conv2D(128, (3, 3), padding=\"same\", activation='relu')(m)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    m = Dropout(0.25)(m)\n",
    "    \n",
    "    m = Conv2D(128, (3, 3), padding=\"same\", activation='relu')(m)\n",
    "    m = MaxPooling2D(2)(m)\n",
    "    m = Dropout(0.25)(m)\n",
    "    \n",
    "    m = Flatten()(m)\n",
    "    m = Dense(128, activation = \"relu\")(m)\n",
    "    \n",
    "    m = Dropout(0.5)(m)\n",
    "    out = Dense(2, activation = \"sigmoid\")(m)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=Adam(learning_rate = 0.0001), loss=\"binary_crossentropy\", metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 30, batch_size = 256, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "#plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(X_test, y_test, batch_size = 256)\n",
    "print('Test Loss, Test Accuracy :', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = model.predict(X_predict)\n",
    "\n",
    "true = 0\n",
    "for i in range(X_predict.shape[0]):\n",
    "    if(np.argmax(P[i]) == np.argmax(y_true[i])):\n",
    "        true = true + 1\n",
    "\n",
    "pre_accuracy = 100 * float(true/X_predict.shape[0])        \n",
    "print('Predict Accuracy: {}' .format(pre_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "* Precision: It can be seen as a measure of a classifier’s exactness. For each class, it is defined as the ratio of true positives to the sum of true and false positives. Said another way, “for all instances classified positive, what percent was correct?”\n",
    "* Recall\n",
    "* f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_true, axis=1), np.argmax(P, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(y_true, axis=1), np.argmax(P, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
